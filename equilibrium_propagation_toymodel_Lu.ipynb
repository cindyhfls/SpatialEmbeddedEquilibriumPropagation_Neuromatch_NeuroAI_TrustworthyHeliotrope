{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cindyhfls/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope/blob/main/equilibrium_propagation_toymodel_Lu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from https://github.com/smonsays/equilibrium-propagation/tree/master \"run_energy_model_mnist.py\"\n",
        "\n",
        "**To-do:**\n",
        "\n",
        "*Week 1 - Make the network architecture and train basic network, decide on the questions*\n",
        "1. We first make a fake \"distance\" matrix by specifying the distance between each of the 1000x1000 pairs of units.\n",
        "2. Implement spatial normalization through energy function?\n",
        "\n",
        "*Week 2 - Calculating metrics to evaluate the network, each person pick a direction to test and produce a summary slide.*"
      ],
      "metadata": {
        "id": "-SFoRIRNUIM8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXyy3RgDRp16",
        "outputId": "e3690ac9-8443-4060-c1d3-5c796307b710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 40 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (40/40), 59.59 KiB | 517.00 KiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "# @title Clone Repository and Setup\n",
        "!git clone https://github.com/cindyhfls/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope/equilibrium-propagation-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re7mL-FKcJaF",
        "outputId": "503290c9-9b9a-45df-950d-a74b50451ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope/equilibrium-propagation-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "\n",
        "from lib import config, data, energy, train, utils"
      ],
      "metadata": {
        "id": "EHmlbpfzcE28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install torchlens and other utilities for visualization/RSA?\n",
        "!pip install torchlens --quiet\n",
        "!pip install rsatoolbox --quiet\n",
        "\n",
        "import torchlens,rsatoolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "wBSNmhO-WmmH",
        "outputId": "e18533dd-0d90-4960-b456-03982b5f3936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/83.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(model, imgs, return_layers, plot='none'):\n",
        "    \"\"\"\n",
        "    Extracts features from specified layers of the model.\n",
        "\n",
        "    Inputs:\n",
        "    - model (torch.nn.Module): The model from which to extract features.\n",
        "    - imgs (torch.Tensor): Batch of input images.\n",
        "    - return_layers (list): List of layer names from which to extract features.\n",
        "    - plot (str): Option to plot the features. Default is 'none'.\n",
        "\n",
        "    Outputs:\n",
        "    - model_features (dict): A dictionary with layer names as keys and extracted features as values.\n",
        "    \"\"\"\n",
        "    model_history = tl.log_forward_pass(model, imgs, layers_to_save='all', vis_opt=plot)\n",
        "    model_features = {}\n",
        "    for layer in return_layers:\n",
        "        model_features[layer] = model_history[layer].tensor_contents.flatten(1)\n",
        "\n",
        "    return model_features"
      ],
      "metadata": {
        "id": "eGaTAdGDYziP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper functions for parsing input\n",
        "def load_default_config(energy):\n",
        "    \"\"\"\n",
        "    Load default parameter configuration from file.\n",
        "\n",
        "    Args:\n",
        "        tasks: String with the energy name\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of default parameters for the given energy\n",
        "    \"\"\"\n",
        "    if energy == \"restr_hopfield\":\n",
        "        default_config = \"etc/energy_restr_hopfield.json\"\n",
        "    elif energy == \"cond_gaussian\":\n",
        "        default_config = \"etc/energy_cond_gaussian.json\"\n",
        "    else:\n",
        "        raise ValueError(\"Energy based model \\\"{}\\\" not defined.\".format(energy))\n",
        "\n",
        "    with open(default_config) as config_json_file:\n",
        "        cfg = json.load(config_json_file)\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def parse_shell_args(args):\n",
        "    \"\"\"\n",
        "    Parse shell arguments for this script.\n",
        "\n",
        "    Args:\n",
        "        args: List of shell arguments\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of shell arguments\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Train an energy-based model on MNIST using Equilibrium Propagation.\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=argparse.SUPPRESS,\n",
        "                        help=\"Size of mini batches during training.\")\n",
        "    parser.add_argument(\"--c_energy\", choices=[\"cross_entropy\", \"squared_error\"],\n",
        "                        default=argparse.SUPPRESS, help=\"Supervised learning cost function.\")\n",
        "    parser.add_argument(\"--dimensions\", type=int, nargs=\"+\",\n",
        "                        default=argparse.SUPPRESS, help=\"Dimensions of the neural network.\")\n",
        "    parser.add_argument(\"--energy\", choices=[\"cond_gaussian\", \"restr_hopfield\"],\n",
        "                        default=\"cond_gaussian\", help=\"Type of energy-based model.\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=argparse.SUPPRESS,\n",
        "                        help=\"Number of epochs to train.\")\n",
        "    parser.add_argument(\"--fast_ff_init\", action='store_true', default=argparse.SUPPRESS,\n",
        "                        help=\"Flag to enable fast feedforward initialization.\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=argparse.SUPPRESS,\n",
        "                        help=\"Learning rate of the optimizer.\")\n",
        "    parser.add_argument(\"--log_dir\", type=str, default=\"\",\n",
        "                        help=\"Subdirectory within ./log/ to store logs.\")\n",
        "    parser.add_argument(\"--nonlinearity\", choices=[\"leaky_relu\", \"relu\", \"sigmoid\", \"tanh\"],\n",
        "                        default=argparse.SUPPRESS, help=\"Nonlinearity between network layers.\")\n",
        "    parser.add_argument(\"--optimizer\", choices=[\"adam\", \"adagrad\", \"sgd\"],\n",
        "                        default=argparse.SUPPRESS, help=\"Optimizer used to train the model.\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=argparse.SUPPRESS,\n",
        "                        help=\"Random seed for pytorch\")\n",
        "\n",
        "    return vars(parser.parse_args(args))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GEkgL8VwS8nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.argv = ['','--energy', 'restr_hopfield', '--epochs', '1']\n",
        "\n",
        "# Parse shell arguments as input configuration\n",
        "user_config = parse_shell_args(sys.argv[1:])\n",
        "\n",
        "# Load default parameter configuration from file for the specified energy-based model\n",
        "cfg = load_default_config(user_config[\"energy\"])\n",
        "\n",
        "# Overwrite default parameters with user configuration where applicable\n",
        "cfg.update(user_config)\n",
        "\n",
        "# Setup global logger and logging directory\n",
        "config.setup_logging(cfg[\"energy\"] + \"_\" + cfg[\"c_energy\"] + \"_\" + cfg[\"dataset\"],\n",
        "                      dir=cfg['log_dir'])"
      ],
      "metadata": {
        "id": "tivHcdFXTeW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main function run_energy_model_mnist\n",
        "\n",
        "\"\"\"\n",
        "Main script.\n",
        "\n",
        "Args:\n",
        "    cfg: Dictionary defining parameters of the run\n",
        "\"\"\"\n",
        "# Initialize seed if specified (might slow down the model)\n",
        "if cfg['seed'] is not None:\n",
        "    torch.manual_seed(cfg['seed'])\n",
        "\n",
        "# Create the cost function to be optimized by the model\n",
        "c_energy = utils.create_cost(cfg['c_energy'], cfg['beta'])\n",
        "\n",
        "# Create activation functions for every layer as a list\n",
        "phi = utils.create_activations(cfg['nonlinearity'], len(cfg['dimensions']))\n",
        "\n",
        "# Initialize energy based model\n",
        "if cfg[\"energy\"] == \"restr_hopfield\":\n",
        "    model = energy.RestrictedHopfield(\n",
        "        cfg['dimensions'], c_energy, cfg['batch_size'], phi).to(config.device)\n",
        "elif cfg[\"energy\"] == \"cond_gaussian\":\n",
        "    model = energy.ConditionalGaussian(\n",
        "        cfg['dimensions'], c_energy, cfg['batch_size'], phi).to(config.device)\n",
        "else:\n",
        "    raise ValueError(f'Energy based model \\\"{cfg[\"energy\"]}\\\" not defined.')\n",
        "\n",
        "# Define optimizer (may include l2 regularization via weight_decay)\n",
        "w_optimizer = utils.create_optimizer(model, cfg['optimizer'],  lr=cfg['learning_rate'])\n",
        "\n",
        "# Create torch data loaders with the MNIST data set\n",
        "mnist_train, mnist_test = data.create_mnist_loaders(cfg['batch_size'])\n",
        "\n",
        "logging.info(\"Start training with parametrization:\\n{}\".format(\n",
        "    json.dumps(cfg, indent=4, sort_keys=True)))\n",
        "\n",
        "for epoch in range(1, cfg['epochs'] + 1):\n",
        "    # Training\n",
        "    train.train(model, mnist_train, cfg['dynamics'], w_optimizer, cfg[\"fast_ff_init\"])\n",
        "\n",
        "    # Testing\n",
        "    test_acc, test_energy = train.test(model, mnist_test, cfg['dynamics'], cfg[\"fast_ff_init\"])\n",
        "\n",
        "    # Logging\n",
        "    logging.info(\n",
        "        \"epoch: {} \\t test_acc: {:.4f} \\t mean_E: {:.4f}\".format(\n",
        "            epoch, test_acc, test_energy)\n",
        "    )"
      ],
      "metadata": {
        "id": "-RznO9RdTReC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize model\n",
        "print(model)\n",
        "# can't get this to work\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('log/example')\n",
        "writer.add_graph(model)\n",
        "writer.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "1dooKXW1WeXN",
        "outputId": "bf6ceee3-3d24-4fc9-9acc-ced7b6bdf8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RestrictedHopfield(\n",
            "  (W): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=1000, bias=True)\n",
            "    (1): Linear(in_features=1000, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "example_kwarg_inputs should be a dict\n",
            "Error occurs, No graph saved\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "example_kwarg_inputs should be a dict",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a07937b4dca0>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# default `log_dir` is \"runs\" - we'll be more specific here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log/example'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m             self._get_file_writer().add_graph(\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_strict_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             )\n\u001b[1;32m    891\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error occurs, No graph saved\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_set_model_to_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_strict_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_kwarg_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"example_kwarg_inputs should be a dict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         return trace_module(\n\u001b[1;32m    821\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: example_kwarg_inputs should be a dict"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=log"
      ],
      "metadata": {
        "id": "62o6LkyzeqmQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
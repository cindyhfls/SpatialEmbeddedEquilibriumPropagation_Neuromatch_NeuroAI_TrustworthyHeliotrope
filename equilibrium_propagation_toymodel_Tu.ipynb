{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNC/NocYTAhXGqacSh55lZw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cindyhfls/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope/blob/main/equilibrium_propagation_toymodel_Tu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from https://github.com/smonsays/equilibrium-propagation/tree/master \"run_energy_model_mnist.py\"\n",
        "\n",
        "**To-do:**\n",
        "\n",
        "*Week 1 - Make the network architecture and train basic network, decide on the questions*\n",
        "1. We first make a fake \"distance\" matrix by specifying the distance between each of the 1000x1000 pairs of units.\n",
        "2. Implement spatial normalization through energy function?\n",
        "\n",
        "*Week 2 - Calculating metrics to evaluate the network, each person pick a direction to test and produce a summary slide.*"
      ],
      "metadata": {
        "id": "-SFoRIRNUIM8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXyy3RgDRp16"
      },
      "outputs": [],
      "source": [
        "# @title Clone Repository and Setup\n",
        "!git clone https://github.com/cindyhfls/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope.git -b BackPropDev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope/equilibrium-propagation-master/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re7mL-FKcJaF",
        "outputId": "cc0f9d0b-57dd-4e38-ecc5-3d6c9c65e9e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SpatialEmbeddedEquilibriumPropagation_Neuromatch_NeuroAI_TrustworthyHeliotrope/equilibrium-propagation-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "\n",
        "from lib import config, data, energy, train, utils"
      ],
      "metadata": {
        "id": "EHmlbpfzcE28"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install torchlens and other utilities for visualization/RSA?\n",
        "!pip install torchlens --quiet\n",
        "!pip install rsatoolbox --quiet\n",
        "!pip install torchviz --quiet\n",
        "\n",
        "import torchlens,rsatoolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBSNmhO-WmmH",
        "outputId": "8796579c-4406-4197-c309-331a1557c9de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper functions for parsing input\n",
        "def load_default_config(energy):\n",
        "    \"\"\"\n",
        "    Load default parameter configuration from file.\n",
        "\n",
        "    Args:\n",
        "        tasks: String with the energy name\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of default parameters for the given energy\n",
        "    \"\"\"\n",
        "    if energy == \"restr_hopfield\":\n",
        "        default_config = \"etc/energy_restr_hopfield.json\"\n",
        "    elif energy == \"cond_gaussian\":\n",
        "        default_config = \"etc/energy_cond_gaussian.json\"\n",
        "    else:\n",
        "        raise ValueError(\"Energy based model \\\"{}\\\" not defined.\".format(energy))\n",
        "\n",
        "    with open(default_config) as config_json_file:\n",
        "        cfg = json.load(config_json_file)\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def parse_shell_args(args):\n",
        "    \"\"\"\n",
        "    Parse shell arguments for this script.\n",
        "\n",
        "    Args:\n",
        "        args: List of shell arguments\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of shell arguments\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Train an energy-based model on MNIST using Equilibrium Propagation.\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=argparse.SUPPRESS,\n",
        "                        help=\"Size of mini batches during training.\")\n",
        "    parser.add_argument(\"--c_energy\", choices=[\"cross_entropy\", \"squared_error\"],\n",
        "                        default=argparse.SUPPRESS, help=\"Supervised learning cost function.\")\n",
        "    parser.add_argument(\"--dimensions\", type=int, nargs=\"+\",\n",
        "                        default=argparse.SUPPRESS, help=\"Dimensions of the neural network.\")\n",
        "    parser.add_argument(\"--energy\", choices=[\"cond_gaussian\", \"restr_hopfield\"],\n",
        "                        default=\"cond_gaussian\", help=\"Type of energy-based model.\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=argparse.SUPPRESS,\n",
        "                        help=\"Number of epochs to train.\")\n",
        "    parser.add_argument(\"--fast_ff_init\", action='store_true', default=argparse.SUPPRESS,\n",
        "                        help=\"Flag to enable fast feedforward initialization.\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=argparse.SUPPRESS,\n",
        "                        help=\"Learning rate of the optimizer.\")\n",
        "    parser.add_argument(\"--log_dir\", type=str, default=\"\",\n",
        "                        help=\"Subdirectory within ./log/ to store logs.\")\n",
        "    parser.add_argument(\"--nonlinearity\", choices=[\"leaky_relu\", \"relu\", \"sigmoid\", \"tanh\"],\n",
        "                        default=argparse.SUPPRESS, help=\"Nonlinearity between network layers.\")\n",
        "    parser.add_argument(\"--optimizer\", choices=[\"adam\", \"adagrad\", \"sgd\"],\n",
        "                        default=argparse.SUPPRESS, help=\"Optimizer used to train the model.\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=argparse.SUPPRESS,\n",
        "                        help=\"Random seed for pytorch\")\n",
        "\n",
        "    return vars(parser.parse_args(args))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GEkgL8VwS8nx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change this input to make configuration\n",
        "\n",
        "sys.argv = ['','--energy', 'restr_hopfield', '--epochs', '1']\n",
        "\n",
        "# Parse shell arguments as input configuration\n",
        "user_config = parse_shell_args(sys.argv[1:])\n",
        "\n",
        "# Load default parameter configuration from file for the specified energy-based model\n",
        "cfg = load_default_config(user_config[\"energy\"])\n",
        "\n",
        "# Overwrite default parameters with user configuration where applicable\n",
        "cfg.update(user_config)\n",
        "\n",
        "# Setup global logger and logging directory\n",
        "config.setup_logging(cfg[\"energy\"] + \"_\" + cfg[\"c_energy\"] + \"_\" + cfg[\"dataset\"],\n",
        "                      dir=cfg['log_dir'])"
      ],
      "metadata": {
        "id": "tivHcdFXTeW4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load data\n",
        "\n",
        "# Create torch data loaders with the MNIST data set\n",
        "data_train, data_test = data.create_mnist_loaders(cfg['batch_size'])\n"
      ],
      "metadata": {
        "id": "T2ueIP6d82Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main function run_energy_model_mnist\n",
        "\n",
        "\"\"\"\n",
        "Main script.\n",
        "\n",
        "Args:\n",
        "    cfg: Dictionary defining parameters of the run\n",
        "\"\"\"\n",
        "\n",
        "# Initialize seed if specified (might slow down the model)\n",
        "if cfg['seed'] is not None:\n",
        "    torch.manual_seed(cfg['seed'])\n",
        "\n",
        "# Create the cost function to be optimized by the model\n",
        "c_energy = utils.create_cost(cfg['c_energy'], cfg['beta'])\n",
        "\n",
        "# Create activation functions for every layer as a list\n",
        "phi = utils.create_activations(cfg['nonlinearity'], len(cfg['dimensions']))\n",
        "\n",
        "# Initialize energy based model\n",
        "if cfg[\"energy\"] == \"restr_hopfield\":\n",
        "    model = energy.RestrictedHopfield(\n",
        "        cfg['dimensions'], c_energy, cfg['batch_size'], phi).to(config.device)\n",
        "elif cfg[\"energy\"] == \"cond_gaussian\":\n",
        "    model = energy.ConditionalGaussian(\n",
        "        cfg['dimensions'], c_energy, cfg['batch_size'], phi).to(config.device)\n",
        "else:\n",
        "    raise ValueError(f'Energy based model \\\"{cfg[\"energy\"]}\\\" not defined.')\n",
        "\n",
        "# Define optimizer (may include l2 regularization via weight_decay)\n",
        "w_optimizer = utils.create_optimizer(model, cfg['optimizer'],  lr=cfg['learning_rate'])\n",
        "\n",
        "logging.info(\"Start training with parametrization:\\n{}\".format(\n",
        "    json.dumps(cfg, indent=4, sort_keys=True)))\n",
        "\n",
        "for epoch in range(1, cfg['epochs'] + 1):\n",
        "    # Training\n",
        "    train.train(model, data_train, cfg['dynamics'], w_optimizer, cfg[\"fast_ff_init\"])\n",
        "\n",
        "    # Testing\n",
        "    test_acc, test_energy = train.test(model, data_test, cfg['dynamics'], cfg[\"fast_ff_init\"])\n",
        "\n",
        "    # Logging\n",
        "    logging.info(\n",
        "        \"epoch: {} \\t test_acc: {:.4f} \\t mean_E: {:.4f}\".format(\n",
        "            epoch, test_acc, test_energy)\n",
        "    )"
      ],
      "metadata": {
        "id": "-RznO9RdTReC",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main function run_backprop_model_mnist (reuse the cfg before for hyperparameters, model architecture etc.)\n",
        "# Create activation functions for every layer as a list\n",
        "phi = utils.create_activations(cfg['nonlinearity'], len(cfg['dimensions']))\n",
        "\n",
        "if cfg['c_energy'] == 'CrossEntropy':\n",
        "  criterion = nn.functional.CrossEntropyLoss()\n",
        "elif cft['c_energy'] == 'SquaredLoss':\n",
        "  criterion = nn.functional.mse_loss()\n",
        "\n",
        "model = energy.MLP(\n",
        "    cfg['dimensions'], criterion,cfg['batch_size'],phi).to(config.device)"
      ],
      "metadata": {
        "id": "IRHbjOHc8GHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.functiona.mse_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "if2AFjGlIIqK",
        "outputId": "a0bddb68-d1ce-45ac-a0aa-9278030a0b40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-62c787748445>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize model\n",
        "print(model)\n",
        "import graphviz\n",
        "\n",
        "def visualize_hopfield_structure(model):\n",
        "    dot = graphviz.Digraph()\n",
        "    layers = len(model.W)  # Assuming model.W contains weights between layers\n",
        "\n",
        "    # Add nodes for each layer\n",
        "    for i in range(layers + 1):  # +1 because there are n+1 layers if there are n sets of weights\n",
        "        dot.node(f'Layer {i}', f'Layer {i}')\n",
        "\n",
        "    # Add edges between nodes\n",
        "    for i in range(layers):\n",
        "        dot.edge(f'Layer {i}', f'Layer {i + 1}', label=f'Weights {i}')\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Assuming 'model' is an instance of RestrictedHopfield\n",
        "model_dot = visualize_hopfield_structure(model)\n",
        "model_dot.render('hopfield_structure', format='png', view=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "1dooKXW1WeXN",
        "outputId": "5f5e1e23-b8da-453b-83c9-348f4b78be2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RestrictedHopfield(\n",
            "  (W): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=1000, bias=True)\n",
            "    (1): Linear(in_features=1000, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hopfield_structure.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "\n",
        "def visualize_hopfield_connections(model):\n",
        "    dot = graphviz.Digraph(engine='dot', format='png')\n",
        "\n",
        "    # Assuming model has an attribute 'W' that represents the weights between layers\n",
        "    # and 'u' that might represent activations or states of each layer\n",
        "    layers = len(model.W)  # Number of weight matrices should indicate the number of connections\n",
        "    units_per_layer = [model.u[i].shape[1] for i in range(layers + 1)]  # +1 to include output layer units\n",
        "\n",
        "    # Create subgraphs for layers\n",
        "    for i in range(layers + 1):\n",
        "        with dot.subgraph(name=f'cluster_{i}') as c:\n",
        "            c.attr(label=f'Layer {i}')\n",
        "            for j in range(units_per_layer[i]):\n",
        "                c.node(f'n_{i}_{j}', f'Unit {j}')\n",
        "\n",
        "    # Connect units between layers\n",
        "    for i in range(layers):\n",
        "        for j in range(model.W[i].weight.shape[0]):  # Rows in the weight matrix for layer i\n",
        "            for k in range(model.W[i].weight.shape[1]):  # Columns in the weight matrix for layer i\n",
        "                weight = model.W[i].weight[j, k].item()  # Getting the weight from PyTorch model\n",
        "                dot.edge(f'n_{i}_{j}', f'n_{i+1}_{k}', label=f'{weight:.2f}')\n",
        "\n",
        "    return dot\n",
        "\n",
        "# Create a visualization of the model structure\n",
        "# Assuming 'model' is properly defined with weights 'W' and states 'u'\n",
        "model_dot = visualize_hopfield_connections(model)\n",
        "model_dot.render('hopfield_network', view=True)"
      ],
      "metadata": {
        "id": "tNeDTUXNuniq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "VxxEkTS77sd0",
        "outputId": "a95f71b1-00f9-4df7-9d3c-32361a1063bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1f8a688cae5d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF7LSwDWxoXz",
        "outputId": "1c351c00-821c-4854-e686-e42c5e9e9ae9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 100,\n",
              " 'beta': 1,\n",
              " 'c_energy': 'squared_error',\n",
              " 'dataset': 'mnist',\n",
              " 'dimensions': [784, 1000, 10],\n",
              " 'dynamics': {'dt': 0.1, 'n_relax': 50, 'tau': 1, 'tol': 0},\n",
              " 'energy': 'restr_hopfield',\n",
              " 'epochs': 1,\n",
              " 'fast_ff_init': False,\n",
              " 'learning_rate': 0.001,\n",
              " 'nonlinearity': 'sigmoid',\n",
              " 'optimizer': 'adam',\n",
              " 'seed': None,\n",
              " 'log_dir': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can't get this to work\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('log/example')\n",
        "writer.add_graph(model)\n",
        "writer.close()\n",
        "\n",
        "\n",
        "\n",
        "!tensorboard --logdir=log"
      ],
      "metadata": {
        "id": "62o6LkyzeqmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(model, imgs, return_layers, plot='none'):\n",
        "    \"\"\"\n",
        "    Extracts features from specified layers of the model.\n",
        "\n",
        "    Inputs:\n",
        "    - model (torch.nn.Module): The model from which to extract features.\n",
        "    - imgs (torch.Tensor): Batch of input images.\n",
        "    - return_layers (list): List of layer names from which to extract features.\n",
        "    - plot (str): Option to plot the features. Default is 'none'.\n",
        "\n",
        "    Outputs:\n",
        "    - model_features (dict): A dictionary with layer names as keys and extracted features as values.\n",
        "    \"\"\"\n",
        "    model_history = tl.log_forward_pass(model, imgs, layers_to_save='all', vis_opt=plot)\n",
        "    model_features = {}\n",
        "    for layer in return_layers:\n",
        "        model_features[layer] = model_history[layer].tensor_contents.flatten(1)\n",
        "\n",
        "    return model_features"
      ],
      "metadata": {
        "id": "eGaTAdGDYziP"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}